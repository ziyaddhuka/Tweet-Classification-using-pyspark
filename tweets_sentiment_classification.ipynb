{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "tweets_sentiment_classification",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 427306627538836
    },
    "colab": {
      "name": "tweets_sentiment_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "943e74a6-c840-472b-9003-a35fbadd5ac2"
        },
        "id": "wmPQ6Hk75put",
        "outputId": "31b0e22d-001b-4bee-9843-6bc3e886e4e2"
      },
      "source": [
        "sc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">Out[1]: </div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[1]: </div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"/?o=847800122948729#setting/sparkui/0711-223008-caws196/driver-8883139692944589691\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[8]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Databricks Shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=847800122948729#setting/sparkui/0711-223008-caws196/driver-8883139692944589691\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        ",
              "textData": null,
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "htmlSandbox",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "657d85e8-4c1c-4e32-ba1d-ce17edb141c5"
        },
        "id": "bX0dJPAr5puz",
        "outputId": "d5934d9a-b292-4ab6-e662-85ad3bd9a34e"
      },
      "source": [
        "from pyspark import SparkFiles\n",
        "from  pyspark.ml.feature import StopWordsRemover, RegexTokenizer, HashingTF, StringIndexer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark import SparkFiles\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import boto3\n",
        "from botocore.client import Config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "1fa8e2ec-5465-4c0d-ad5c-c5768256ca8e"
        },
        "id": "sSnQSnQK5pu0",
        "outputId": "c8648681-d5ba-4933-cfb4-56fdf6ac72d5"
      },
      "source": [
        "def write_output_to_aws(output_file_name, output_predictions):\n",
        "  ACCESS_KEY = ''\n",
        "  SECRET_KEY = ''\n",
        "  AWS_BUCKET_NAME = \"\"\n",
        "  s3 = boto3.resource('s3', aws_access_key_id = ACCESS_KEY, aws_secret_access_key =SECRET_KEY, config = Config(signature_version = 's3v4') )\n",
        "  op = pd.DataFrame(output_predictions)\n",
        "  op.columns = ['Tweet','probabilities', 'prediction', 'true_label']\n",
        "  csv_buffer = StringIO()\n",
        "  op.to_csv(csv_buffer)\n",
        "  # s3_resource = boto3.resource('s3')\n",
        "#   timestamp = int(time.time())\n",
        "  file_name = f'output_new/{output_file_name}.csv'\n",
        "  s3.Object(AWS_BUCKET_NAME, file_name).put(Body=csv_buffer.getvalue(),ACL='public-read')\n",
        "#   you can change the region or else add the region dynamically\n",
        "  region= \"us-west-1\"\n",
        "\n",
        "  url = f\"https://{AWS_BUCKET_NAME}.s3.{region}.amazonaws.com/{file_name}\"\n",
        "  print(\"------------------------------------\")\n",
        "  print(\"download url from aws: \", url)\n",
        "  print(\"------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b18e2851-b602-4698-9247-0f60a0787db6"
        },
        "id": "kntQ1q-u5pu1",
        "outputId": "f18d5f5c-ddc4-4f59-ec32-0ced7db79dd3"
      },
      "source": [
        "def train_and_get_tweets_predictions(url, output_file_name):\n",
        "  spark.sparkContext.addFile(url)\n",
        "  # df = spark.read.csv('/FileStore/tables/Tweets.csv', header= True, inferSchema= True)\n",
        "#   Loading the file\n",
        "  df = spark.read.csv(\"file://\"+SparkFiles.get('Tweets.csv'), header= True, inferSchema= True)\n",
        "#   Selecting only tweets and sentiment\n",
        "  data = df.select(['airline_sentiment','text'])\n",
        "#   Removing empty rows if any\n",
        "  data = data.where(data.text.isNotNull())\n",
        "\n",
        "\n",
        "# initializing tokenizers, stopwords_remover, hashingTF, string indexer and Logistic Regression\n",
        "  tokenizer = RegexTokenizer(pattern=r'(?:\\p{Punct}|\\s)+', inputCol='text', outputCol='text_temp')\n",
        "  remover = StopWordsRemover(inputCol='text_temp', outputCol='text_intermediate')\n",
        "  hashing_tf_words = HashingTF(inputCol=\"text_intermediate\", outputCol=\"features\")\n",
        "  string_indexer = StringIndexer(inputCol='airline_sentiment', outputCol='label')\n",
        "  lr = LogisticRegression(regParam=0.3, elasticNetParam=0, maxIter = 10000)\n",
        "# fitting them in a pipeline\n",
        "  pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf_words, string_indexer, lr])\n",
        "# building a parameter grid for hypertuning\n",
        "  paramGrid = ParamGridBuilder() \\\n",
        "      .addGrid(hashing_tf_words.numFeatures, [10, 100, 1000]) \\\n",
        "      .addGrid(lr.regParam, [0.2, 0.4, 0.6, 0.8]) \\\n",
        "      .addGrid(lr.maxIter, [100,1000,10000]) \\\n",
        "      .build()\n",
        "\n",
        "#   crossvalidator\n",
        "  crossval = CrossValidator(estimator=pipeline,\n",
        "                            estimatorParamMaps=paramGrid,\n",
        "                            evaluator=MulticlassClassificationEvaluator(),\n",
        "                            numFolds=2,\n",
        "                            )\n",
        "\n",
        "  train, test = data.randomSplit([0.8, 0.2], seed = 1)\n",
        "  cvModel = crossval.fit(train)\n",
        "  prediction = cvModel.transform(test)\n",
        "\n",
        "#   evaluating the accuracy\n",
        "  evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
        "  accuracy = evaluator.evaluate(prediction)\n",
        "  print(\"------------------------\")\n",
        "  print(\"accuracy is :\",accuracy)\n",
        "  print(\"------------------------\")\n",
        "  output_to_show = prediction.select([\"text\", \"probability\",\"prediction\",\"label\"])\n",
        "  write_output_to_aws(output_file_name, output_to_show.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\"></div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "75ce9ea9-7d0c-4422-9063-c613801b8067"
        },
        "id": "66_jAil_5pu2",
        "outputId": "15ab3705-d976-4395-93ef-2363d3c1bffb"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "# bucket url\n",
        "  url = \"\"\n",
        "  output_file_name = \"output_tweets\"\n",
        "  train_and_get_tweets_predictions(url, output_file_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>\n",
              "<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n",
              "  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n",
              "------------------------\n",
              "accuracy is : 0.737874097007224\n",
              "------------------------\n",
              "------------------------------------\n",
              "download url from aws:  https://bigdataproject.s3.us-west-1.amazonaws.com/output_new/output_tweets.csv\n",
              "------------------------------------\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": [],
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n------------------------\naccuracy is : 0.737874097007224\n------------------------\n------------------------------------\ndownload url from aws:  https://bigdataproject.s3.us-west-1.amazonaws.com/output_new/output_tweets.csv\n------------------------------------\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "27dae100-a13e-4661-b10e-4577758ff157"
        },
        "id": "hslcAf5M5pu3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}